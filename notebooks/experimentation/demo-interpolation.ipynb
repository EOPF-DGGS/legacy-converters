{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# interpolation to healpix\n",
    "\n",
    "**Note**: Use `pixi run jupyterlab` to start a jupyterlab instance from within the project.\n",
    "\n",
    "The UTM tile comes with a affine transform, which we can use to simplify the transformation.\n",
    "\n",
    "For others, like `conditions/geometry` which doesn't have an affine transform, and `conditions/meteorology`, which is not UTM, we'll have to use a different approach (potentially just nearest neighbour interpolation while keeping the original coordinates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac_client\n",
    "import xarray as xr\n",
    "import xdggs\n",
    "\n",
    "import legacy_converters\n",
    "\n",
    "xr.set_options(keep_attrs=True, display_expand_attrs=False, use_opt_einsum=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## query the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access cloud-optimized Sentinel-2 data via the EOPF STAC catalog\n",
    "catalog = pystac_client.Client.open(\"https://stac.core.eopf.eodc.eu\")\n",
    "\n",
    "# Define oceanographic study area and time window\n",
    "LON, LAT = -4.5, 48  # Bay of Biscay - known for consistent wave patterns\n",
    "date = \"2025-06-17/2025-06-17\"\n",
    "\n",
    "# Search criteria optimized for wave analysis\n",
    "\n",
    "collection = \"sentinel-2-l1c\"\n",
    "items = list(\n",
    "    catalog.search(\n",
    "        datetime=date,\n",
    "        collections=[collection],\n",
    "        intersects=dict(type=\"Point\", coordinates=[LON, LAT]),\n",
    "        query={\n",
    "            \"eo:cloud_cover\": {\n",
    "                \"lt\": 20\n",
    "            },  # Cloud cover < 20% ensures clear ocean surface\n",
    "            \"view:sun_elevation\": {\n",
    "                \"gt\": 25\n",
    "            },  # Filter for high sun elevation > 25° (→ sun zenith angle < 65°),\n",
    "            # which places the sun near the zenith.\n",
    "        },\n",
    "    ).items()\n",
    ")\n",
    "\n",
    "for item in items:\n",
    "    print(f\"✅ {item.id}\")\n",
    "\n",
    "item = items[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## open the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = xr.open_datatree(\n",
    "    item.assets[\"product\"].href, engine=\"zarr\", chunks={}, decode_timedelta=True\n",
    ")\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## subset to a region of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Create raster indexes (from `rasterix`). This will allow us to keep the affine transform up-to-date, even after the subsetting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_dt = dt.grid4earth.create_raster_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dt = raster_dt.sel(\n",
    "    {\n",
    "        \"x\": slice(\n",
    "            dt[\"conditions/geometry/x\"][0],\n",
    "            dt[\"conditions/geometry/x\"][1],\n",
    "        ),\n",
    "        \"y\": slice(\n",
    "            dt[\"conditions/geometry/y\"][0],\n",
    "            dt[\"conditions/geometry/y\"][1],\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "small_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Interpolate to healpix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Select the dataset to interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = small_dt[\"/measurements/reflectance/r10m\"].to_dataset()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "infer the target grid.\n",
    "\n",
    "Note: the method on `grid4earth` handles ellipsoids, while `xdggs` does not (yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_info = xdggs.HealpixInfo(level=19, indexing_scheme=\"nested\")\n",
    "target_grid = ds.grid4earth.infer_healpix_grid(grid_info)\n",
    "target_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Nearest neighbour interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Compute interpolation weights\n",
    "\n",
    "Note: this is very fast because we're using a functional representation of the source grid (a affine transform) to compute neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "weights = legacy_converters.interpolation.weights.nearest_affine(ds, target_grid)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Apply the interpolation with a sparse matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "regridded = ds.map(\n",
    "    lambda var: xr.dot(\n",
    "        weights.chunk({\"cells\": 2000000}).variable, var, dim=[\"x\", \"y\"]\n",
    "    ).assign_coords(weights.dggs.coord.coords)\n",
    ")\n",
    "regridded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Actually compute the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "computed = regridded.compute().map(lambda var: var.copy(data=var.data.todense()))\n",
    "computed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Display the result:\n",
    "\n",
    "Note: `xdggs` does not yet support ellipsoidal coordinates, hence the shift compared to the base map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "computed[\"b03\"].dggs.explore(alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Bilinear interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Compute interpolation weights\n",
    "\n",
    "Note: this is very fast because we're using a functional representation of the source grid (a affine transform) to compute neighbours.\n",
    "\n",
    "Further improvements in the future:\n",
    "- boundary treatment\n",
    "- optimizations for sparse matrix-vector products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "weights = legacy_converters.interpolation.weights.bilinear_affine(ds, target_grid)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Apply the interpolation with a sparse matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "regridded = ds.map(\n",
    "    lambda var: xr.dot(\n",
    "        weights.chunk({\"cells\": 2000000}).variable, var, dim=[\"x\", \"y\"]\n",
    "    ).assign_coords(weights.dggs.coord.coords)\n",
    ")\n",
    "regridded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Actually compute the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "computed = regridded.compute().map(lambda var: var.copy(data=var.data.todense()))\n",
    "computed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Display the result:\n",
    "\n",
    "Note: `xdggs` does not yet support ellipsoidal coordinates, hence the shift compared to the base map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "computed[\"b03\"].dggs.explore(alpha=0.8)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
